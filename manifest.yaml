# We are using a GCE disk as persistent storage for the Hub
# and for each individual user node.
#
# A volume for the hub is automatically provisioned b/c its pvc
# is using a storage class. There is no need to manually provision
# any disks on the cluster.
#
# When a single user pod is spun up, a corresponding pvc is
# dynamically provisioned by kubespawner. If a pvc for that user
# already exists, the pod mounts to the existing pvc.
#

kind: StorageClass
apiVersion: storage.k8s.io/v1beta1
metadata:
  name: gce-standard-storage
provisioner: kubernetes.io/gce-pd
parameters:
  type: pd-standard
  zone: us-west1-a
---
kind: ConfigMap
apiVersion: v1
metadata:
  name: hub-config
# TODO: Make secrets more secure
data:
  # Used to authenticate the culler to the hub. This string was generated with `openssl rand -hex 32`.
  auth.jhub-token.cull: "13fdff1305cd883e49223908186a63294922dadb59b5d1122473041f160c4b03"
  oauth.client-id.google: "92948014362-c7jc8k20co1e4eqmg8095818htadijat.apps.googleusercontent.com"
  oauth.client-secret.google: "BabUWSqHd4ZekBqiaur4S1cm"
  # Used to authenticate the hub to the proxy. This string was generated with `pwgen 64`.
  # Please generate a new one for your own deployment!
  auth.jhub-token.proxy: "Kev4Shai9phai0Eez2aiyaefaepheutei3baehaiseipheef1Ah2cah4xeaquohr"
---
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: data8-workdir
  annotations:
    volume.beta.kubernetes.io/storage-class: gce-standard-storage
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
---
apiVersion: v1
kind: Service
metadata:
  name: proxy-api
spec:
  selector:
    name: proxy-pod
  ports:
    - protocol: TCP
      port: 8001
      targetPort: 8001
---
apiVersion: v1
kind: Service
metadata:
  name: proxy-public
spec:
  type: LoadBalancer
  selector:
    name: proxy-pod
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8000
---
apiVersion: v1
kind: Service
metadata:
  name: hub
spec:
  selector:
    name: hub-pod
  ports:
    - protocol: TCP
      port: 8081
      targetPort: 8081
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: hub-deployment
spec:
  replicas: 1
  template:
    metadata:
      labels:
        name: hub-pod
    spec:
      volumes:
      - name: data8-workdir-volume
        persistentVolumeClaim:
          claimName: data8-workdir
      containers:
      - name: hub-proxy-container
        image: data8/jupyterhub-k8s-hub:data8_jupyterhubv3
        imagePullPolicy: Always
        volumeMounts:
          - mountPath: /srv/jupyterhub
            name: data8-workdir-volume
        env:
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: CULL_JHUB_TOKEN
          valueFrom:
            configMapKeyRef:
              name: hub-config
              key: auth.jhub-token.cull
        - name: GOOGLE_OAUTH_CLIENT_ID
          valueFrom:
            configMapKeyRef:
              name: hub-config
              key: oauth.client-id.google
        - name: GOOGLE_OAUTH_CLIENT_SECRET
          valueFrom:
            configMapKeyRef:
              name: hub-config
              key: oauth.client-secret.google
        - name: OAUTH_CALLBACK_URL
          value: http://derrick-jhub.calblueprint.org/hub/oauth_callback
        - name: CONFIGPROXY_AUTH_TOKEN
          valueFrom:
            configMapKeyRef:
              name: hub-config
              key: auth.jhub-token.proxy
        ports:
          - containerPort: 8081
            name: hub
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: proxy-deployment
spec:
  replicas: 1
  template:
    metadata:
      labels:
        name: proxy-pod
    spec:
      containers:
      - name: proxy-container
        image: yuvipanda/nchp:v1
        env:
          - name: CONFIGPROXY_AUTH_TOKEN
            valueFrom:
              configMapKeyRef:
                name: hub-config
                key: auth.jhub-token.proxy
        ports:
          - containerPort: 8000
            name: proxy-public
          - containerPort: 8001
            name: api
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: cull-deployment
spec:
  replicas: 1
  template:
    metadata:
      labels:
        name: cull-pod
    spec:
      containers:
        - name: cull-container
          image: data8/jupyterhub-k8s-cull:master
          command:
            - /bin/sh
            - -c
          args: ['python /srv/cull/cull_idle_servers.py --timeout=3600 --cull_every=600 --url=http://${HUB_SERVICE_HOST}:${HUB_SERVICE_PORT}/hub']
          env:
          - name: JPY_API_TOKEN
            valueFrom:
              configMapKeyRef:
                name: hub-config
                key: auth.jhub-token.cull
